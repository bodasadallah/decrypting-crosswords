{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import os\n",
    "from utils import get_dataset,get_ans_words_chard\n",
    "from datasets import load_dataset\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "from tqdm import tqdm   \n",
    "import emoji\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset_path = 'data/clue_json/guardian/naive_random/test.json'\n",
    "# train_dataset_path = 'data/clue_json/guardian/naive_random/train.json'\n",
    "\n",
    "# eval_dataset = load_dataset('json', data_files=eval_dataset_path, split='train')\n",
    "\n",
    "# train_dataset = load_dataset('json', data_files=train_dataset_path, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(output, correct_answer):\n",
    "\n",
    "    cleaned_length_error = True\n",
    "    original_length_error = True\n",
    "    original_correct = False\n",
    "    cleaned_correct =False\n",
    "\n",
    "    output = output.strip()\n",
    "    correct_answer = correct_answer.strip()\n",
    "\n",
    "    if output== correct_answer:\n",
    "        original_correct = True\n",
    "    if len(output) == len(correct_answer):\n",
    "        original_length_error = False\n",
    "\n",
    "\n",
    "\n",
    "    original_words = output.lower().split(' ')\n",
    "\n",
    "    answer_lengths  =  [len(x) for x in  correct_answer.split(' ')]\n",
    "    answer = []\n",
    "    cleaned_answer = output\n",
    "    if len(original_words) >= len(answer_lengths):\n",
    "        for idx, length in enumerate(answer_lengths):\n",
    "            answer.append(original_words[idx][:length])\n",
    "\n",
    "\n",
    "        cleaned_answer = ' '.join(answer).strip()\n",
    "        if cleaned_answer == correct_answer.strip():\n",
    "            cleaned_correct = True\n",
    "        if len(cleaned_answer) == len(correct_answer.strip()):\n",
    "            cleaned_length_error = False\n",
    "    \n",
    "\n",
    "    return {'original_length_error': original_length_error,\n",
    "            'cleaned_length_error': cleaned_length_error,\n",
    "            'original_correct': original_correct,\n",
    "            'cleaned_correct': cleaned_correct,\n",
    "            'cleaned_answer': cleaned_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(clue):\n",
    "\n",
    "    n_words, n_chars = get_ans_words_chard(clue)\n",
    "    return f'''The next line is a clue for a cryptic crossword. The clue consists of a definition part and a wordplay part. The answer consists of {n_words} words, and the number of characters in the answer is {n_chars}. Output only the answer.\n",
    "clue:\n",
    "{clue}\n",
    "answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(temp, file_name):\n",
    "\n",
    "    ## Initialize the file if it does not exist\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name,'w') as file:\n",
    "            json.dump([],file)\n",
    "    \n",
    "    file_data = []\n",
    "    with open(file_name,'r') as file:\n",
    "        file_data = json.load(file)\n",
    "\n",
    "    file_data.extend(temp)\n",
    "    with open(file_name,'w') as file:\n",
    "        # file.seek(0)\n",
    "        json.dump(file_data,file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset,generate_prompt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "errors = 0\n",
    "\n",
    "model_name = 'gpt-3.5-turbo'\n",
    "chatgpt_outputs_file = f'outputs/new_experiments/chatgpt_outputs/{model_name}_3_shot_indicator_outputs_disjoint.json'\n",
    "\n",
    "shots = 3\n",
    "prompt_head='''The next line is a clue for a cryptic crossword. The clue consists of a definition part and a wordplay part. The answer consists of {n_words} words, and the number of characters in the answer is {n_chars}. Output only the answer.'''\n",
    "dataset_path='data/clue_json/guardian/naive_random/test.json'\n",
    "\n",
    "dataset = load_dataset('json', data_files=dataset_path, split='train')\n",
    "dataset = dataset.remove_columns(['idx'])\n",
    "dataset = dataset.rename_column('target', 'labels')\n",
    "dataset = dataset.rename_column('input', 'clue')\n",
    "# dataset = get_dataset(dataset_path=dataset_path,\n",
    "#                         split='test',prompt_head = prompt_head,\n",
    "#                         shots=shots,\n",
    "#                         dataset_type='old',\n",
    "#                         indicator_type_shots = 1,\n",
    "#                         indicators_dict_path='data/indicators_examples.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28476 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/28476 [02:22<108:29:57, 13.72s/it] "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "num_examples = len(dataset)\n",
    "save_temps = []\n",
    "\n",
    "offset = 0\n",
    "# with open(chatgpt_outputs_file, 'a') as f:\n",
    "for idx ,clue in enumerate(tqdm(dataset.select(range(offset,num_examples)))):\n",
    "    \n",
    "    idx = idx + offset\n",
    "\n",
    "    # clue['prompt'] = clue['prompt'] + '\\n\\n### Response:\\n'\n",
    "    \n",
    "    try:\n",
    "      # correct_answers.append(clue[\"target\"])\n",
    "      clue_message = {\"role\": \"user\", \"content\": create_prompt(clue['clue'])}#clue['prompt']}\n",
    "      completion = client.chat.completions.create(\n",
    "        # request_timeout=15,\n",
    "        model=model_name,\n",
    "\n",
    "        messages=[\n",
    "          # system_message,\n",
    "          clue_message\n",
    "        ]\n",
    "      )\n",
    "\n",
    "      response = completion.choices[0].message.content.lower()\n",
    "      save_temps.append({'idx': idx, 'clue': clue['clue'],'response': response, 'target': clue[\"labels\"]})\n",
    "    except:\n",
    "      save_temps.append({'idx': idx})\n",
    "      errors += 1\n",
    "\n",
    "    if idx % 100 == 0 or idx == num_examples - 1:\n",
    "      save_results(save_temps,chatgpt_outputs_file)\n",
    "      save_temps = []\n",
    "\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clue': 'Achy shaking stopped by iodine, salt and kaolin (5,4)', 'labels': 'china clay', 'prompt': '### Instruction: The next line is a clue for a cryptic crossword. The clue consists of a definition part and a wordplay part. The answer consists of 2 words, and the number of characters in the answer is 5,4. Output only the answer.\\n\\n### Input:\\nAchy shaking stopped by iodine, salt and kaolin (5,4)'}\n"
     ]
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: The next line is a clue for a cryptic crossword. The clue consists of a definition part and a wordplay part. The answer consists of 2 words, and the number of characters in the answer is 5,4. Output only the answer.\n",
      "\n",
      "### Input:\n",
      "Achy shaking stopped by iodine, salt and kaolin (5,4)\n"
     ]
    }
   ],
   "source": [
    "print(x['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'response': 'a little', 'target': 'a trifle'}\n",
      "{'idx': 1, 'response': 'marseille', 'target': 'jerusalem'}\n",
      "{'idx': 2, 'response': 'tower', 'target': 'tower'}\n",
      "{'idx': 3, 'response': 'sad', 'target': 'down'}\n",
      "{'idx': 4, 'response': 'greenpeace', 'target': 'greenpeace'}\n"
     ]
    }
   ],
   "source": [
    "# with open('chatgpt_outputs/gpt-3.5-turbo_3shot_learning_outputs.json') as f:\n",
    "#     d = json.load(f)\n",
    "#     for i in d:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('outputs/new_experiments/chatgpt_outputs/gpt-3.5-turbo_3shot_learning_outputs_disjoint.json') as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "\n",
    "chatgpt_outputs = []\n",
    "correct_answers = []\n",
    "errors = 0\n",
    "for i in d:\n",
    "    if 'response' in i:\n",
    "        chatgpt_outputs.append(i['response'])\n",
    "        correct_answers.append(i['target'])\n",
    "    else:\n",
    "        errors += 1\n",
    "\n",
    "assert len(chatgpt_outputs) == len(correct_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32636\n",
      "818|stoppi|ng + peace|niks - iks = stopping|cinderella\n",
      "17119|to secure the first course baked in pastry, you need to take the following steps:\n",
      "1. the first course refers to the letter at the beginning of the word.\n",
      "2. \"baked in pastry\" indicates that the rest of the word is formed by rearranging the letters of \"pastry\".thus, the answer to this clue is \"april fool\".|en croute\n",
      "19520|sad | which refers to the girlfriend being sad and sand | which refers to the sandwiches being cut.|shed a tear\n",
      "19542|there are two possible answers for this clue:\n",
      "1) tyndale - tyndale is a bible translator known for his work in translating the bible into english. it can be split as \"ty\" (the first person in french) + \"nd\" (the first person in latin) + \"ale\" (a city in france). the answer has a total of 6 characters.\n",
      "2) jerome - jerome is a bible translator known for his work in translating the bible into latin. it can be split as \"jero\" (the first person in french) + \"me\" (a city in france). the answer has a total of 6 characters.both answers are valid depending on whether the clue refers to a bible translator who translated into french or latin.|jerome\n",
      "21137|how to solve:\n",
      "1. the clue suggests that we are looking for a \"sort of book\" that is instructive.\n",
      "2. the next part, \"couple picked up,\" indicates that we need to take the first letters of two words.\n",
      "3. the final part, \"in house,\" suggests that the answer can be found within the word \"house.\"\n",
      "4. the answer is \"how to,\" which has 3 letters, followed by \"us,\" which has 2 letters.answer: how to|how to\n",
      "25992\n",
      "26032\n",
      "26037\n",
      "26060\n",
      "26076\n",
      "26079\n"
     ]
    }
   ],
   "source": [
    "# chatgpt_outputs = []\n",
    "# correct_answers = []\n",
    "\n",
    "# with open(f'chatgpt_outputs/gpt-3.5-turbo_outputs.txt', 'r') as f:\n",
    "#   lines = f.readlines()\n",
    "\n",
    "# cleaned_lines = []\n",
    "# for i,l in enumerate(lines):\n",
    "#   if not l[0].isdigit():\n",
    "#     cleaned_lines[-1] = cleaned_lines[-1].strip() + l.strip()\n",
    "#   else:\n",
    "#     cleaned_lines.append(l.strip())\n",
    "\n",
    "\n",
    "# print(len(cleaned_lines))\n",
    "# for l in cleaned_lines:\n",
    "\n",
    "#   ll = l.strip().split('|')\n",
    "#   if len(ll) != 3:\n",
    "#     print(l)\n",
    "\n",
    "#   ## if this line doesn't has 3 components, it means that the response is empty, so we ignore it\n",
    "#   if len(ll) < 3:\n",
    "#     continue\n",
    "\n",
    "#     idx, response, target = ll\n",
    "#   splitted = l.strip().split('|')\n",
    "#   idx = splitted[0]\n",
    "#   target = splitted[-1]\n",
    "#   response = ' '.join(splitted[1:-1])\n",
    "  \n",
    "#   chatgpt_outputs.append(response)\n",
    "#   correct_answers.append(target)\n",
    "\n",
    "\n",
    "# assert len(chatgpt_outputs) == len(correct_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Examples 16202\n",
      "\n",
      " Cleaned ACCURACY:  0.02950253055178373\n",
      "\n",
      "Orginal ACCURACY:  0.028514998148376745\n",
      "\n",
      "Length error:  0.26731267744722875\n",
      "\n",
      "Original Length error:  0.42254042710776446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################33 Evaluation ##################3\n",
    "\n",
    "assert len(chatgpt_outputs) == len(correct_answers)\n",
    "\n",
    "num_examples = len(chatgpt_outputs)\n",
    "\n",
    "original_correct = 0\n",
    "cleaned_correct = 0\n",
    "original_length_error = 0\n",
    "cleaned_length_error = 0\n",
    "\n",
    "\n",
    "save_file = 'gpt-3.5-turbo_0-shot_random_learning_outputs.txt'\n",
    "dataset_path='naive_random'\n",
    "\n",
    "with open(save_file, 'w') as f:\n",
    "\n",
    "\n",
    "    for idx, (output, correct_answer) in enumerate(zip(chatgpt_outputs, correct_answers)):\n",
    "        results = process_outputs(output, correct_answer)\n",
    "\n",
    "        original_correct += results['original_correct']\n",
    "        cleaned_correct += results['cleaned_correct']\n",
    "        original_length_error += results['original_length_error']\n",
    "        cleaned_length_error += results['cleaned_length_error']\n",
    "        cleaned_answer = results['cleaned_answer']\n",
    "\n",
    "        f.write(f'Original output: {output}\\n')\n",
    "        if results['cleaned_correct'] :\n",
    "            f.write(emoji.emojize(f'{cleaned_answer} | {correct_answer}  :check_mark_button: \\n'))\n",
    "        else:\n",
    "            f.write(emoji.emojize(f'{cleaned_answer} | {correct_answer}  :cross_mark: \\n'))\n",
    "\n",
    "        f.write('----------------------------------------------------- \\n\\n')\n",
    "\n",
    "    f.write('\\n\\n')\n",
    "    f.flush()\n",
    "\n",
    "\n",
    "    f.seek(0)\n",
    "    f.write(f'Dataset: {dataset_path}\\n')\n",
    "\n",
    "    f.write(f'Number of Examples {num_examples}\\n')\n",
    "    print(f'Number of Examples {num_examples}\\n')\n",
    "\n",
    "    f.write(f' Cleaned ACCURACY:  { float (cleaned_correct / num_examples)}\\n')\n",
    "    print(f' Cleaned ACCURACY:  { float (cleaned_correct / num_examples)}\\n')\n",
    "\n",
    "    f.write(f'Orginal ACCURACY:  { float (original_correct / num_examples)}\\n')\n",
    "    print(f'Orginal ACCURACY:  { float (original_correct / num_examples)}\\n')\n",
    "\n",
    "    f.write(f'Length error:  { float ((cleaned_length_error / num_examples) )}\\n')\n",
    "    print(f'Length error:  { float ((cleaned_length_error / num_examples) )}\\n')\n",
    "\n",
    "    f.write(f'Original Length error:  { float ((original_length_error / num_examples) )}\\n')\n",
    "    print(f'Original Length error:  { float ((original_length_error / num_examples) )}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "musical a trifle\n",
      "7 8\n",
      "marseille jerusalem\n",
      "9 9\n",
      "magnet tower\n",
      "6 5\n",
      "soap down\n",
      "4 4\n",
      "conserving greenpeace\n",
      "10 10\n",
      "eye ooh\n",
      "3 3\n",
      "sagaal lissome\n",
      "6 7\n",
      "silhouette televise\n",
      "10 8\n",
      "safeguard (9) patroller\n",
      "13 9\n",
      "city wall holy city\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "# print(correct_answers)\n",
    "# print(chatgpt_outputs)\n",
    "\n",
    "for i,j in zip(chatgpt_outputs, correct_answers):\n",
    "    print(i,j)\n",
    "    print(len(i), len(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 samples results: \n",
    "\n",
    "Original correct: 0.06\n",
    "Cleaned correct: 0.06\n",
    "Original length error: 0.33\n",
    "Cleaned length error: 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
